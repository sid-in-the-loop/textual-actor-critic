wandb: WARNING `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.
wandb: Currently logged in as: ssmurali (ssmurali-cmu) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
+++ hostname
+++ whoami
++ MACHINE_SPECIFIC_RAY_DIR=/tmp/ray_babel-o9-16_ssmurali_14504
++ mkdir -p /tmp/ray_babel-o9-16_ssmurali_14504
++ export RAY_TMPDIR=/tmp/ray_babel-o9-16_ssmurali_14504
++ RAY_TMPDIR=/tmp/ray_babel-o9-16_ssmurali_14504
+++ nvidia-smi --query-gpu=name --format=csv,noheader
+++ head -n 1
++ GPU_MODEL='NVIDIA L40S'
++ [[ NVIDIA L40S == *\A\6\0\0\0* ]]
++ [[ NVIDIA L40S == *\L\4\0\S* ]]
++ echo 'Detected NVIDIA L40S, disabling NCCL P2P'
++ export NCCL_P2P_DISABLE=1
++ NCCL_P2P_DISABLE=1
++ export VLLM_ATTENTION_BACKEND=XFORMERS
++ VLLM_ATTENTION_BACKEND=XFORMERS
++ export HYDRA_FULL_ERROR=1
++ HYDRA_FULL_ERROR=1
++ export RAY_DEBUG=0
++ RAY_DEBUG=0
++ export WANDB_API_KEY=1e255990efc627595f0c805e0546cc7f0ff08b17
++ WANDB_API_KEY=1e255990efc627595f0c805e0546cc7f0ff08b17
++ export HF_TOKEN=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
++ HF_TOKEN=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
++ export HUGGING_FACE_HUB_TOKEN=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
++ HUGGING_FACE_HUB_TOKEN=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
++ export OPENAI_API_KEY=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
++ OPENAI_API_KEY=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
++ export OPENAI_API_KEY=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
++ OPENAI_API_KEY=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
++ MODEL_DIR=/data/group_data/cx_group/verl_agent_shared
++ train_data_size=32
++ val_data_size=16
++ group_size=8
++ python3 -m verl.trainer.main_ppo algorithm.adv_estimator=grpo algorithm.use_kl_in_reward=False algorithm.compute_mean_std_cross_all_data=False data.train_files=dummy_data/text/train.parquet data.val_files=dummy_data/text/val.parquet data.train_batch_size=32 data.val_batch_size=16 data.max_prompt_length=20000 data.max_response_length=1024 data.filter_overlong_prompts=True data.truncation=error data.return_raw_chat=True actor_rollout_ref.rollout.temperature=1.0 actor_rollout_ref.model.path=/data/group_data/cx_group/behavior_priming/checkpoint/qwen3_1.7b/web_qwen_sft_behavior/checkpoint-924 actor_rollout_ref.model.use_remove_padding=True actor_rollout_ref.actor.use_kl_loss=True actor_rollout_ref.actor.kl_loss_coef=0.001 actor_rollout_ref.actor.kl_loss_type=low_var_kl actor_rollout_ref.actor.optim.lr=1e-6 actor_rollout_ref.actor.use_dynamic_bsz=True actor_rollout_ref.actor.ppo_max_token_len_per_gpu=22000 actor_rollout_ref.actor.ppo_mini_batch_size=32 actor_rollout_ref.actor.fsdp_config.param_offload=False actor_rollout_ref.actor.fsdp_config.optimizer_offload=False actor_rollout_ref.actor.ulysses_sequence_parallel_size=1 actor_rollout_ref.model.enable_activation_offload=False actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=64 actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.name=vllm actor_rollout_ref.rollout.gpu_memory_utilization=0.5 actor_rollout_ref.rollout.enable_chunked_prefill=False actor_rollout_ref.rollout.enforce_eager=True actor_rollout_ref.rollout.free_cache_engine=True actor_rollout_ref.rollout.val_kwargs.temperature=0.4 actor_rollout_ref.rollout.val_kwargs.do_sample=True actor_rollout_ref.rollout.max_num_batched_tokens=22000 actor_rollout_ref.rollout.max_model_len=22000 actor_rollout_ref.rollout.disable_log_stats=False actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=64 actor_rollout_ref.ref.fsdp_config.param_offload=True actor_rollout_ref.ref.max_model_len=22000 actor_rollout_ref.actor.use_invalid_action_penalty=True env.rule_reward_coef=0 env.env_name=deepresearch env.dataset=afm env.seed=0 env.rollout.n=8 env.rollout.k=1 env.max_steps=8 env.use_explicit_thinking=False env.use_critique=False env.replace_input=False env.use_rule_reward=False env.rule_number=5 env.use_dense_reward=False env.belief_shaped_grpo.enable=True env.belief_shaped_grpo.alpha=1.0 env.belief_shaped_grpo.max_candidates=1 trainer.critic_warmup=0 'trainer.logger=[console,wandb]' trainer.project_name=DeepResearch_RL trainer.experiment_name=deepresearch_1.7b_belief_shaped_grpo_fast_reward_resume trainer.n_gpus_per_node=4 trainer.nnodes=1 trainer.save_freq=5 trainer.test_freq=25 trainer.total_epochs=1 trainer.total_training_steps=50 trainer.resume_mode=auto trainer.default_local_dir=/data/group_data/cx_group/verl_agent_shared/checkpoint/deepresearch_1.7b_belief_shaped_grpo_fast_reward trainer.val_before_train=False trainer.log_val_generations=1
2025-12-22 11:48:16,072	INFO worker.py:1942 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
[2025-12-22 11:48:16,076 I 14512 14512] logging.cc:303: Set ray log level from environment variable RAY_BACKEND_LOG_LEVEL to 1
[33m(raylet)[0m [2025-12-22 11:48:17,321 I 15511 15511] logging.cc:303: Set ray log level from environment variable RAY_BACKEND_LOG_LEVEL to 1
[36m(TaskRunner pid=19257)[0m Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.
[36m(TaskRunner pid=19257)[0m Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.
[36m(TaskRunner pid=19257)[0m Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.
[36m(TaskRunner pid=19257)[0m See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.
[33m(raylet)[0m [2025-12-22 11:48:17,976 I 19257 19257] logging.cc:303: Set ray log level from environment variable RAY_BACKEND_LOG_LEVEL to 1
[36m(TaskRunner pid=19257)[0m building DeepResearchMultiProcessEnv with config: {'verbose': False, 'log_dir': '/home/ssmurali/verl-agent/agent_system/environments/env_package/deepresearch/../../../../deepresearch_logs_Belief/afm_train/20251222_114825', 'answer_dir': '/home/ssmurali/verl-agent/agent_system/environments/env_package/deepresearch/../../../../deepresearch_outputs_Belief/afm_train/20251222_114825', 'max_turns': 8, 'num_docs': 1, 'num_docs_to_read': 1, 'search_reminder_turn': 3, 'final_report_reminder_turn': 5, 'max_context_length': 8000, 'mode': 'qa', 'search_engine': 'serper', 'use_explicit_thinking': False, 'use_critique': False}
[36m(TaskRunner pid=19257)[0m Init DeepResearchMultiProcessEnv, env_num: 32, group_n: 8, num_processes: 256
[36m(TaskRunner pid=19257)[0m building DeepResearchMultiProcessEnv with config: {'verbose': False, 'log_dir': '/home/ssmurali/verl-agent/agent_system/environments/env_package/deepresearch/../../../../deepresearch_logs_Belief/afm_val/20251222_114825', 'answer_dir': '/home/ssmurali/verl-agent/agent_system/environments/env_package/deepresearch/../../../../deepresearch_outputs_Belief/afm_val/20251222_114825', 'max_turns': 8, 'num_docs': 1, 'num_docs_to_read': 1, 'search_reminder_turn': 3, 'final_report_reminder_turn': 5, 'max_context_length': 8000, 'mode': 'qa', 'search_engine': 'serper', 'use_explicit_thinking': False, 'use_critique': False}
[36m(TaskRunner pid=19257)[0m Init DeepResearchMultiProcessEnv, env_num: 16, group_n: 1, num_processes: 16
[33m(raylet)[0m [2025-12-22 11:48:29,048 I 19651 19651] logging.cc:303: Set ray log level from environment variable RAY_BACKEND_LOG_LEVEL to 1
[36m(TaskRunner pid=19257)[0m Filtering prompts longer than 20000 tokens:   0%|          | 0/1600 [00:00<?, ? examples/s]
[36m(TaskRunner pid=19257)[0m Filtering prompts longer than 20000 tokens:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1000/1600 [00:00<00:00, 2850.31 examples/s]
[36m(TaskRunner pid=19257)[0m Filtering prompts longer than 20000 tokens: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1600/1600 [00:00<00:00, 3064.80 examples/s]Filtering prompts longer than 20000 tokens: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1600/1600 [00:00<00:00, 2993.24 examples/s]
[36m(TaskRunner pid=19257)[0m Filtering prompts longer than 20000 tokens:   0%|          | 0/512 [00:00<?, ? examples/s]
[36m(TaskRunner pid=19257)[0m Filtering prompts longer than 20000 tokens: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [00:00<00:00, 3391.84 examples/s]Filtering prompts longer than 20000 tokens: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512/512 [00:00<00:00, 3237.93 examples/s]
[36m(TaskRunner pid=19257)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(pid=19457)[0m Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.
[36m(pid=19457)[0m Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.
[36m(pid=19457)[0m Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.
[36m(pid=19457)[0m See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.
[33m(raylet)[0m [2025-12-22 11:48:33,529 I 24111 24111] logging.cc:303: Set ray log level from environment variable RAY_BACKEND_LOG_LEVEL to 1[32m [repeated 127x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(TaskRunner pid=19257)[0m WARNING:2025-12-22 11:48:36,173:Waiting for register center actor lrA9Vi_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(pid=23190)[0m Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.[32m [repeated 93x across cluster][0m
[36m(pid=23190)[0m Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.[32m [repeated 93x across cluster][0m
[36m(pid=23190)[0m Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.[32m [repeated 93x across cluster][0m
[36m(pid=23190)[0m See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.[32m [repeated 93x across cluster][0m
[33m(raylet)[0m [2025-12-22 11:48:39,075 I 29484 29484] logging.cc:303: Set ray log level from environment variable RAY_BACKEND_LOG_LEVEL to 1[32m [repeated 64x across cluster][0m
[36m(pid=26877)[0m Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.[32m [repeated 51x across cluster][0m
[36m(pid=26877)[0m Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.[32m [repeated 51x across cluster][0m
[36m(pid=26877)[0m Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.[32m [repeated 51x across cluster][0m
[36m(pid=26877)[0m See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.[32m [repeated 51x across cluster][0m
[33m(raylet)[0m [2025-12-22 11:48:44,534 I 32196 32196] logging.cc:303: Set ray log level from environment variable RAY_BACKEND_LOG_LEVEL to 1[32m [repeated 45x across cluster][0m
[36m(pid=30008)[0m Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.[32m [repeated 51x across cluster][0m
[36m(pid=30008)[0m Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.[32m [repeated 51x across cluster][0m
[36m(pid=30008)[0m Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.[32m [repeated 51x across cluster][0m
[36m(pid=30008)[0m See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.[32m [repeated 51x across cluster][0m
[33m(raylet)[0m [2025-12-22 11:48:49,478 I 34392 34392] logging.cc:303: Set ray log level from environment variable RAY_BACKEND_LOG_LEVEL to 1[32m [repeated 33x across cluster][0m
[36m(pid=33222)[0m Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.[32m [repeated 52x across cluster][0m
[36m(pid=33222)[0m Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.[32m [repeated 52x across cluster][0m
[36m(pid=33222)[0m Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.[32m [repeated 52x across cluster][0m
[36m(pid=33222)[0m See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.[32m [repeated 52x across cluster][0m
[33m(raylet)[0m [2025-12-22 11:48:51,284 I 34714 34714] logging.cc:303: Set ray log level from environment variable RAY_BACKEND_LOG_LEVEL to 1[32m [repeated 4x across cluster][0m
[36m(pid=34468)[0m Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.[32m [repeated 21x across cluster][0m
[36m(pid=34468)[0m Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.[32m [repeated 21x across cluster][0m
[36m(pid=34468)[0m Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.[32m [repeated 21x across cluster][0m
[36m(pid=34468)[0m See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.[32m [repeated 21x across cluster][0m
[36m(TaskRunner pid=19257)[0m WARNING:2025-12-22 11:49:06,214:Waiting for register center actor lrA9Vi_register_center to be ready. Elapsed time: 30 seconds out of 300 seconds.
[36m(pid=34714)[0m Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.[32m [repeated 3x across cluster][0m
[36m(pid=34714)[0m Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.[32m [repeated 3x across cluster][0m
[36m(pid=34714)[0m Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.[32m [repeated 3x across cluster][0m
[36m(pid=34714)[0m See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.[32m [repeated 3x across cluster][0m
[33m(raylet)[0m [2025-12-22 11:49:32,513 I 42191 42191] logging.cc:303: Set ray log level from environment variable RAY_BACKEND_LOG_LEVEL to 1
[36m(WorkerDict pid=42365)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[33m(raylet)[0m [2025-12-22 11:49:33,192 I 42366 42366] logging.cc:303: Set ray log level from environment variable RAY_BACKEND_LOG_LEVEL to 1[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=30844)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen3ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=30844)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen3Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`
[36m(WorkerDict pid=42366)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=30844)[0m /home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=30844)[0m   warnings.warn(
[36m(WorkerDict pid=42366)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen3Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", dtype=torch.float16)`[32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=42366)[0m `torch_dtype` is deprecated! Use `dtype` instead![32m [repeated 4x across cluster][0m
[36m(TaskRunner pid=19257)[0m wandb: WARNING `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.
[36m(TaskRunner pid=19257)[0m wandb: Currently logged in as: ssmurali (ssmurali-cmu) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(TaskRunner pid=19257)[0m wandb: Tracking run with wandb version 0.21.3
[36m(TaskRunner pid=19257)[0m wandb: Run data is saved locally in /home/ssmurali/verl-agent/wandb/run-20251222_115031-0lnwhdu9
[36m(TaskRunner pid=19257)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(TaskRunner pid=19257)[0m wandb: Syncing run deepresearch_1.7b_belief_shaped_grpo_fast_reward_resume
[36m(TaskRunner pid=19257)[0m wandb: â­ï¸ View project at https://wandb.ai/ssmurali-cmu/DeepResearch_RL
[36m(TaskRunner pid=19257)[0m wandb: ðŸš€ View run at https://wandb.ai/ssmurali-cmu/DeepResearch_RL/runs/0lnwhdu9
[36m(TaskRunner pid=19257)[0m Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [00:00<?, ?it/s]
[36m(WorkerDict pid=42366)[0m /home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=42366)[0m   warnings.warn([32m [repeated 3x across cluster][0m
[36m(TaskRunner pid=19257)[0m Reset 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m /home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.
[36m(TaskRunner pid=19257)[0m   return _methods._mean(a, axis=axis, dtype=dtype,
[36m(TaskRunner pid=19257)[0m /home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide
[36m(TaskRunner pid=19257)[0m   ret = ret.dtype.type(ret / rcount)
[36m(TaskRunner pid=19257)[0m Training Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [46:34<22:30:48, 2794.77s/it]
[36m(TaskRunner pid=19257)[0m Reset 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Training Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [1:27:53<20:17:21, 2608.61s/it]Reset 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Training Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [2:13:00<19:54:13, 2653.83s/it]Reset 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Training Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 24/50 [3:09:43<21:18:04, 2949.40s/it]Reset 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Reset 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m Step 16 workers (env_num=16, group_n=1, dataset_name=afm_val)
[36m(TaskRunner pid=19257)[0m wandb: WARNING Tried to log to step 25 that is less than the current step 57. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
[36m(TaskRunner pid=19257)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [7:42:55<54:08:43, 7796.96s/it]
[36m(TaskRunner pid=19257)[0m Reset 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m Step 256 workers (env_num=32, group_n=8, dataset_name=afm_train)
[36m(TaskRunner pid=19257)[0m 
[36m(TaskRunner pid=19257)[0m wandb: updating run metadata
[36m(TaskRunner pid=19257)[0m wandb: uploading summary
[36m(TaskRunner pid=19257)[0m wandb:                                                                                
[36m(TaskRunner pid=19257)[0m wandb: 
[36m(TaskRunner pid=19257)[0m wandb: Run history:
[36m(TaskRunner pid=19257)[0m wandb:      actor/entropy_loss â–ˆâ–‚â–…â–
[36m(TaskRunner pid=19257)[0m wandb:         actor/grad_norm â–â–ƒâ–‡â–ˆ
[36m(TaskRunner pid=19257)[0m wandb:           actor/kl_coef â–â–â–â–
[36m(TaskRunner pid=19257)[0m wandb:           actor/kl_loss â–â–ƒâ–„â–ˆ
[36m(TaskRunner pid=19257)[0m wandb:                actor/lr â–â–â–â–
[36m(TaskRunner pid=19257)[0m wandb:       actor/pg_clipfrac â–…â–ƒâ–ˆâ–
[36m(TaskRunner pid=19257)[0m wandb: actor/pg_clipfrac_lower â–â–â–â–
[36m(TaskRunner pid=19257)[0m wandb:           actor/pg_loss â–ˆâ–‡â–‡â–
[36m(TaskRunner pid=19257)[0m wandb:            actor/ppo_kl â–†â–â–ˆâ–ˆ
[36m(TaskRunner pid=19257)[0m wandb:     avg_passed_per_step â–â–â–â–
[36m(TaskRunner pid=19257)[0m wandb:                     +64 ...
[36m(TaskRunner pid=19257)[0m wandb: 
[36m(TaskRunner pid=19257)[0m wandb: Run summary:
[36m(TaskRunner pid=19257)[0m wandb:      actor/entropy_loss 0.65712
[36m(TaskRunner pid=19257)[0m wandb:         actor/grad_norm 5.27741
[36m(TaskRunner pid=19257)[0m wandb:           actor/kl_coef 0.001
[36m(TaskRunner pid=19257)[0m wandb:           actor/kl_loss 0.07699
[36m(TaskRunner pid=19257)[0m wandb:                actor/lr 0.0
[36m(TaskRunner pid=19257)[0m wandb:       actor/pg_clipfrac 0.0051
[36m(TaskRunner pid=19257)[0m wandb: actor/pg_clipfrac_lower 0
[36m(TaskRunner pid=19257)[0m wandb:           actor/pg_loss -1.12932
[36m(TaskRunner pid=19257)[0m wandb:            actor/ppo_kl 0.0005
[36m(TaskRunner pid=19257)[0m wandb:     avg_passed_per_step 0
[36m(TaskRunner pid=19257)[0m wandb:                     +64 ...
[36m(TaskRunner pid=19257)[0m wandb: 
[36m(TaskRunner pid=19257)[0m wandb: ðŸš€ View run deepresearch_1.7b_belief_shaped_grpo_fast_reward_resume at: https://wandb.ai/ssmurali-cmu/DeepResearch_RL/runs/0lnwhdu9
[36m(TaskRunner pid=19257)[0m wandb: â­ï¸ View project at: https://wandb.ai/ssmurali-cmu/DeepResearch_RL
[36m(TaskRunner pid=19257)[0m wandb: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)
[36m(TaskRunner pid=19257)[0m wandb: Find logs at: ./wandb/run-20251222_115031-0lnwhdu9/logs
[36m(TaskRunner pid=19257)[0m Training Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [8:18:07<41:30:38, 5977.54s/it]
Error executing job with overrides: ['algorithm.adv_estimator=grpo', 'algorithm.use_kl_in_reward=False', 'algorithm.compute_mean_std_cross_all_data=False', 'data.train_files=dummy_data/text/train.parquet', 'data.val_files=dummy_data/text/val.parquet', 'data.train_batch_size=32', 'data.val_batch_size=16', 'data.max_prompt_length=20000', 'data.max_response_length=1024', 'data.filter_overlong_prompts=True', 'data.truncation=error', 'data.return_raw_chat=True', 'actor_rollout_ref.rollout.temperature=1.0', 'actor_rollout_ref.model.path=/data/group_data/cx_group/behavior_priming/checkpoint/qwen3_1.7b/web_qwen_sft_behavior/checkpoint-924', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.use_kl_loss=True', 'actor_rollout_ref.actor.kl_loss_coef=0.001', 'actor_rollout_ref.actor.kl_loss_type=low_var_kl', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.actor.use_dynamic_bsz=True', 'actor_rollout_ref.actor.ppo_max_token_len_per_gpu=22000', 'actor_rollout_ref.actor.ppo_mini_batch_size=32', 'actor_rollout_ref.actor.fsdp_config.param_offload=False', 'actor_rollout_ref.actor.fsdp_config.optimizer_offload=False', 'actor_rollout_ref.actor.ulysses_sequence_parallel_size=1', 'actor_rollout_ref.model.enable_activation_offload=False', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=64', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.5', 'actor_rollout_ref.rollout.enable_chunked_prefill=False', 'actor_rollout_ref.rollout.enforce_eager=True', 'actor_rollout_ref.rollout.free_cache_engine=True', 'actor_rollout_ref.rollout.val_kwargs.temperature=0.4', 'actor_rollout_ref.rollout.val_kwargs.do_sample=True', 'actor_rollout_ref.rollout.max_num_batched_tokens=22000', 'actor_rollout_ref.rollout.max_model_len=22000', 'actor_rollout_ref.rollout.disable_log_stats=False', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=64', 'actor_rollout_ref.ref.fsdp_config.param_offload=True', 'actor_rollout_ref.ref.max_model_len=22000', 'actor_rollout_ref.actor.use_invalid_action_penalty=True', 'env.rule_reward_coef=0', 'env.env_name=deepresearch', 'env.dataset=afm', 'env.seed=0', 'env.rollout.n=8', 'env.rollout.k=1', 'env.max_steps=8', 'env.use_explicit_thinking=False', 'env.use_critique=False', 'env.replace_input=False', 'env.use_rule_reward=False', 'env.rule_number=5', 'env.use_dense_reward=False', 'env.belief_shaped_grpo.enable=True', 'env.belief_shaped_grpo.alpha=1.0', 'env.belief_shaped_grpo.max_candidates=1', 'trainer.critic_warmup=0', 'trainer.logger=[console,wandb]', 'trainer.project_name=DeepResearch_RL', 'trainer.experiment_name=deepresearch_1.7b_belief_shaped_grpo_fast_reward_resume', 'trainer.n_gpus_per_node=4', 'trainer.nnodes=1', 'trainer.save_freq=5', 'trainer.test_freq=25', 'trainer.total_epochs=1', 'trainer.total_training_steps=50', 'trainer.resume_mode=auto', 'trainer.default_local_dir=/data/group_data/cx_group/verl_agent_shared/checkpoint/deepresearch_1.7b_belief_shaped_grpo_fast_reward', 'trainer.val_before_train=False', 'trainer.log_val_generations=1']
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/ssmurali/verl-agent/verl/trainer/main_ppo.py", line 269, in <module>
    main()
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
    raise ex
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           ^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
        ^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/verl-agent/verl/trainer/main_ppo.py", line 29, in main
    run_ppo(config)
  File "/home/ssmurali/verl-agent/verl/trainer/main_ppo.py", line 41, in run_ppo
    ray.get(runner.run.remote(config))
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/ray/_private/worker.py", line 2882, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/ray/_private/worker.py", line 968, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::TaskRunner.run()[39m (pid=19257, ip=10.1.1.97, actor_id=1342b2e2121a448dd6d10c8b01000000, repr=<main_ppo.TaskRunner object at 0x14fc32116210>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/verl-agent/verl/trainer/main_ppo.py", line 204, in run
    trainer.fit()
  File "/home/ssmurali/verl-agent/verl/trainer/ppo/ray_trainer.py", line 1128, in fit
    gen_batch_output, belief_trajectories = self.traj_collector.multi_turn_loop(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/verl-agent/agent_system/multi_turn_rollout/rollout_loop.py", line 1071, in multi_turn_loop
    self.vanilla_multi_turn_loop(
  File "/home/ssmurali/verl-agent/agent_system/multi_turn_rollout/rollout_loop.py", line 722, in vanilla_multi_turn_loop
    batch_output = actor_rollout_wg.generate_sequences(batch_input)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/verl-agent/verl/single_controller/ray/base.py", line 51, in __call__
    output = ray.get(output)
             ^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ray.exceptions.RayTaskError(RuntimeError): [36mray::WorkerDict.actor_rollout_generate_sequences()[39m (pid=42365, ip=10.1.1.97, actor_id=13be43904c5accfe0fd6347a01000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x14f6f26a6f30>)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/verl-agent/verl/utils/debug/performance.py", line 80, in f
    return self.log(decorated_function, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/verl-agent/verl/utils/debug/performance.py", line 90, in log
    output = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/verl-agent/verl/workers/rollout/vllm_rollout/vllm_rollout_spmd.py", line 288, in generate_sequences
    outputs = self.inference_engine.generate(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/vllm/utils.py", line 1196, in inner
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/vllm/entrypoints/llm.py", line 473, in generate
    outputs = self._run_engine(use_tqdm=use_tqdm)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/vllm/entrypoints/llm.py", line 1423, in _run_engine
    step_outputs = self.llm_engine.step()
                   ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/vllm/engine/llm_engine.py", line 1412, in step
    outputs = self.model_executor.execute_model(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/vllm/executor/executor_base.py", line 140, in execute_model
    output = self.collective_rpc("execute_model",
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/vllm/worker/worker_base.py", line 420, in execute_model
    output = self.model_runner.execute_model(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/vllm/worker/model_runner.py", line 1820, in execute_model
    output: SamplerOutput = self.sampler(
                            ^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/vllm/model_executor/layers/sampler.py", line 244, in forward
    self._init_sampling_tensors(logits, sampling_metadata)
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/vllm/model_executor/layers/sampler.py", line 208, in _init_sampling_tensors
    do_min_p) = SamplingTensors.from_sampling_metadata(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/vllm/model_executor/sampling_metadata.py", line 480, in from_sampling_metadata
    sampling_tensors = SamplingTensors.from_lists(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/vllm/model_executor/sampling_metadata.py", line 538, in from_lists
    temperatures_t = torch.tensor(
                     ^^^^^^^^^^^^^
RuntimeError: CUDA error: uncorrectable ECC error encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

[36mray::WorkerDict.actor_rollout_generate_sequences()[39m (pid=42365, ip=10.1.1.97, actor_id=13be43904c5accfe0fd6347a01000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x14f6f26a6f30>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/verl-agent/verl/single_controller/ray/base.py", line 645, in func
    return getattr(self.worker_dict[key], name)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/verl-agent/verl/single_controller/base/decorator.py", line 534, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/verl-agent/verl/workers/fsdp_workers.py", line 669, in generate_sequences
    with self.rollout_sharding_manager:
  File "/home/ssmurali/verl-agent/verl/utils/debug/performance.py", line 80, in f
    return self.log(decorated_function, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/verl-agent/verl/utils/debug/performance.py", line 86, in log
    mem_allocated, mem_reserved, mem_used, mem_total = _get_current_mem_info()
                                                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/verl-agent/verl/utils/debug/performance.py", line 40, in _get_current_mem_info
    mem_free, mem_total = get_torch_device().mem_get_info()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ssmurali/miniconda3/envs/verl-agent/lib/python3.12/site-packages/torch/cuda/memory.py", line 738, in mem_get_info
    return torch.cuda.cudart().cudaMemGetInfo(device)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: uncorrectable ECC error encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
