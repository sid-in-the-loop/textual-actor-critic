{
    "answer": "Evaluating Mathematical Reasoning Across Large Language Models",
    "ground_truth": "Evaluation Report on Large Language Models Solving High School Mathematics Questions",
    "rewards": [
        0,
        0,
        0
    ],
    "reward_sum": 0,
    "turns": 3,
    "search count": 2,
    "script count": 0,
    "summary count": 0,
    "context lengths": [
        729,
        1900,
        3005
    ]
}